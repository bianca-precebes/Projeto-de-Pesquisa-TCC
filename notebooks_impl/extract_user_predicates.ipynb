{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Importações e uploads necessários**"
      ],
      "metadata": {
        "id": "sa8wOGMQur86"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-gBooFAum0C"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import re\n",
        "import json\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download pt_core_news_lg"
      ],
      "metadata": {
        "collapsed": true,
        "id": "79oJaLzAvLjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "CSpZi--avOQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_json('/content/drive/MyDrive/final_dataframe.json')\n",
        "df_by_id_chat = df.set_index('_id_chat')\n",
        "df_by_id_chat"
      ],
      "metadata": {
        "id": "A6yDkJI4vQiG",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id_dialogos = df['_id_chat'].unique()\n",
        "id_dialogos.size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLDUHG_QvS_j",
        "outputId": "e49d2a52-f298-4a6c-fb36-0cd00c6eec78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1388"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Funções extras**"
      ],
      "metadata": {
        "id": "DG4e93exuwNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# validação do cpf\n",
        "\n",
        "def valida_cpf(cpf_string):\n",
        "\n",
        "    # retira apenas os dígitos do cpf\n",
        "\n",
        "    numeros = [int(digito) for digito in cpf_string if digito.isdigit()]\n",
        "\n",
        "    quant_digitos = False\n",
        "    validacao1 = False\n",
        "    validacao2 = False\n",
        "\n",
        "    if len(numeros) == 11:\n",
        "        quant_digitos = True\n",
        "\n",
        "        # validação do primeiro dígito\n",
        "\n",
        "        soma_produtos = sum(a*b for a, b in zip (numeros[0:9], range (10, 1, -1)))\n",
        "        digito_esperado = (soma_produtos * 10 % 11) % 10\n",
        "        if numeros[9] == digito_esperado:\n",
        "            validacao1 = True\n",
        "\n",
        "        # validação do segundo dígito\n",
        "\n",
        "        soma_produtos1 = sum(a*b for a, b in zip(numeros [0:10], range (11, 1, -1)))\n",
        "        digito_esperado1 = (soma_produtos1 *10 % 11) % 10\n",
        "        if numeros[10] == digito_esperado1:\n",
        "            validacao2 = True\n",
        "\n",
        "        # validação geral\n",
        "\n",
        "        if quant_digitos == True and validacao1 == True and validacao2 == True:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    else:\n",
        "        return False\n",
        "\n"
      ],
      "metadata": {
        "id": "0Y1YEUCXvW93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mapeamento estado do Ceará\n",
        "\n",
        "ceara_state = {'Ceará', 'Abaiara', 'Acarape', 'Acarau', 'Acaraú', 'Acopiara', 'Aiuaba', 'Alencar', 'Altaneira', 'Antonina do Norte', 'Apuiarés',\n",
        "               'Aquiraz', 'Aracati', 'Aracoiaba', 'Arapipaca', 'Araripe', 'Aratuba', 'Arneiroz', 'Assaré', 'Aurora', 'Baixio', 'Banabuiú', 'Barbalha',\n",
        "               'Barreira', 'Barra do Ceará', 'Barro', 'Barroquinha', 'Baturité', 'Beberibe', 'Bela Cruz', 'Belém', 'Boa Viagem', 'Brejo Santo', 'Brisque',\n",
        "               'Brasilia', 'Buriti', 'Campos Sales', 'Canindé', 'Capistrano', 'Caridade', 'Cariré', 'Caririaçu', 'Cariús', 'Carnaubal', 'Catarina', 'Catunda',\n",
        "               'Cedro', 'Chaval', 'Chinopai', 'Choró', 'Chorozinho', 'Coreaú', 'Crateús', 'Crato', 'Croatá', 'Cruz', 'Deputado Irapuan Pinheiro', 'Ererê',\n",
        "               'Eusebio', 'Farias Brito', 'Forquilha', 'Fortaleza', 'Frecheirinha', 'General Sampaio', 'Graça', 'Granja', 'Groaíras', 'Guaiúba', 'Guaraciaba do Norte',\n",
        "               'Guaramiranga', 'Guaratuba', 'Hidrolândia', 'Ibaretama', 'Ibiapina', 'Icapuí', 'Icó', 'Iguatu', 'Independência', 'Ipaporanga', 'Ipu', 'Ipueiras',\n",
        "               'Iracema', 'Irauçuba', 'Itaitinga', 'Itapagé', 'Itapipoca', 'Itapiúna', 'Itarema', 'Itatira', 'Itauá', 'Itauçú', 'Jardim', 'Jaguaribe', 'Jaguaruana',\n",
        "               'Jangada', 'Jati', 'Jereissati', 'Jijoca de Jericoacoara', 'Juazeiro do Norte', 'Jucás', 'Jurema', 'Limoeiro do Norte', 'Mãe Luiza', 'Maracanaú',\n",
        "               'Maranguape', 'Marco', 'Martinópole', 'Mauriti', 'Meruoca', 'Milagres', 'Milhã', 'Miraíma', 'Mombaça', 'Monsenhor Tabosa', 'Morada Nova', 'Morauju',\n",
        "               'Mucambo', 'Mulungu', 'Nova Olinda', 'Nova Russas', 'Novo Oriente', 'Ocara', 'Orós', 'Pacajus', 'Pacatuba', 'Pacoti', 'Pacuja', 'Palhano', 'Paracuru',\n",
        "               'Paraipaba', 'Parambu', 'Paramoti', 'Pedra Branca', 'Pedra de São Pedro', 'Pentecoste', 'Piquet Carneiro', 'Pires Ferreira', 'Poranga', 'Porteiras',\n",
        "               'Potengi', 'Potiretama', 'Quixeramobim', 'Quixeré', 'Quiterianópolis', 'Redenção', 'Reriutaba', 'Russas', 'Saboeiro', 'Salitre', 'Santa Quitéria',\n",
        "               'Santana do Acaraú', 'Santana do Cariri', 'Santo Antônio de Lisboa', 'São Benedito', 'São Gonçalo do Amarante', 'São João do Jaguaribe',\n",
        "               'São João do Morros', 'São José de Ribamar', 'São Luís do Curu', 'São Mateus', 'São Miguel', 'São Pedro', 'São Tomé', 'São Valério do Sul',\n",
        "               'Senador Pompeu', 'Senador Sá', 'Sobral', 'Solonópole', 'Tabuleiro do Norte', 'Tamboril', 'Tarrafas', 'Tauá', 'Tejuçuoca', 'Tianguá', 'Trairi',\n",
        "               'Tururu', 'Umari', 'Umirim', 'Uruburetama', 'Uruoca', 'Varjota', 'Várzea Alegre', 'Viçosa do Ceará'}"
      ],
      "metadata": {
        "id": "_hlXjkeAUzCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Extração dos predicados do usuário através das entidades**"
      ],
      "metadata": {
        "id": "wZNNsFTAu1Vk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def entities_extraction(phrase):\n",
        "\n",
        "    nlp = spacy.load(\"pt_core_news_lg\")\n",
        "\n",
        "    # criação da regra da entidade e adição ao pipeline\n",
        "\n",
        "    ruler = nlp.add_pipe(\"entity_ruler\", before='ner')\n",
        "\n",
        "    ruler.phrase_matcher = spacy.matcher.PhraseMatcher(nlp.vocab, attr=\"SHAPE\")\n",
        "\n",
        "    # entidades e seus respectivos padrões\n",
        "\n",
        "    patterns = [\n",
        "                    {\n",
        "                        \"label\": \"DOENCA\", \"pattern\": [ {\"LOWER\": \"coronavírus\"} ], \"id\": \"doenca\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"label\": \"DOENCA\", \"pattern\": [ {\"LOWER\": \"covid-19\"} ], \"id\": \"doenca\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"label\": \"ORG\", \"pattern\": \"Governo do Estado\", \"id\": \"organizacao\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"label\": \"TELEFONE\", \"pattern\": [ {\"TEXT\": {\"REGEX\": \"^\\(?\\d{2}\\)?[-.\\s]?\\d{5}[-.\\s]?\\d{4}$\"}} ], \"id\": \"telefone\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"label\": \"TELEFONE\", \"pattern\": '(49) 30492-2949', \"id\": \"telefone\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"label\": \"CPF\", \"pattern\": [ {\"TEXT\": {\"REGEX\": \"(^(\\d){11}$)\"}} ], \"id\": \"cpf\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"label\": \"CEP\", \"pattern\": [ {\"TEXT\": {\"REGEX\": \"(^(\\d){8}$)\"}} ], \"id\": \"cep\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"label\": \"CEP\", \"pattern\": [ {\"TEXT\": {\"REGEX\": \"(^(\\d){5}-(\\d){3}$)\"}} ], \"id\": \"cep\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"label\": \"GENERO\", \"pattern\": [ {\"LOWER\": \"homem\"} ], \"id\": \"genero\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"label\": \"GENERO\", \"pattern\": [ {\"LOWER\": \"mulher\"} ], \"id\": \"genero\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"label\": \"DATA_NASC\", \"pattern\": [ {\"TEXT\": {\"REGEX\": \"^(0[1-9]|[12][0-9]|3[01])\\/(0[1-9]|1[1,2])\\/(19|20)\\d{2}$\"}} ], \"id\": \"data_nascimento\"\n",
        "                    }\n",
        "              ]\n",
        "\n",
        "    # adição dos padrões as regras\n",
        "\n",
        "    ruler.add_patterns(patterns)\n",
        "\n",
        "\n",
        "    # criação do documento a partir do texto\n",
        "\n",
        "    doc = nlp(phrase)\n",
        "\n",
        "    # extração das entidades e suas respectivas labels\n",
        "\n",
        "    find_labels = []\n",
        "\n",
        "    for ent in doc.ents:\n",
        "      if (ent.label_ != \"MISC\" and ent.label_ != \"ORG\" and ent.label_ != \"DOENCA\" and ent.text != \"CPF\" and ent.label_ != \"LOC\"):\n",
        "        if (ent.label_ == \"PER\"):\n",
        "          ent.label_ = \"NOME\"\n",
        "        elif (ent.label_ == \"CPF\"):\n",
        "          if not valida_cpf(ent.text):\n",
        "            ent.label_ = \"TELEFONE\"\n",
        "        #print (ent.text, ent.label_)\n",
        "        find_labels.append(ent.label_)\n",
        "      elif (ent.label_ == \"LOC\"):\n",
        "        if (ent.text in ceara_state):\n",
        "          #print (ent.text, ent.label_)\n",
        "          find_labels.append(ent.label_)\n",
        "\n",
        "\n",
        "    return find_labels\n"
      ],
      "metadata": {
        "id": "XvxJrtyQvbcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predicates():\n",
        "\n",
        "    intentions_predicates = {'send-info-name': False, 'send-info-cpf': False, 'send-info-birthday': False, 'send-info-location': False,\n",
        "                            'send-info-postal-code': False, 'send-info-gender': False, 'send-info-phone-number': False}\n",
        "    entities_predicates = {'have-info-name': False, 'have-info-cpf': False, 'have-info-birthday': False, 'have-info-location': False,\n",
        "                          'have-info-postal-code': False, 'have-info-gender': False, 'have-info-phone-number': False }\n",
        "\n",
        "    return intentions_predicates, entities_predicates"
      ],
      "metadata": {
        "id": "gZ0noMZrvd9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predicates_extraction(user_phrase, int_predicates, ent_predicates):\n",
        "\n",
        "    phrase = user_phrase\n",
        "\n",
        "    list_predicates = entities_extraction(phrase)\n",
        "\n",
        "    intentions_predicates = int_predicates\n",
        "    entities_predicates = ent_predicates\n",
        "    user_predicates = {}\n",
        "    entity_found = \"\"\n",
        "\n",
        "    if (len(list_predicates) == 0):\n",
        "      return intentions_predicates, entities_predicates, user_predicates, entity_found\n",
        "    else:\n",
        "      for i in list_predicates:\n",
        "        if (i == 'NOME'):\n",
        "          entity_found = \"Entidade NOME encontrada\\n\"\n",
        "          intentions_predicates['send-info-name'] = True\n",
        "          entities_predicates['have-info-name'] = True\n",
        "        elif (i == 'CPF'):\n",
        "          entity_found = \"Entidade CPF encontrada\\n\"\n",
        "          intentions_predicates['send-info-cpf'] = True\n",
        "          entities_predicates['have-info-cpf'] = True\n",
        "        elif (i == 'DATA_NASC'):\n",
        "          entity_found = \"Entidade DATA_NASC encontrada\\n\"\n",
        "          intentions_predicates['send-info-birthday'] = True\n",
        "          entities_predicates['have-info-birthday'] = True\n",
        "        elif (i == 'LOC'):\n",
        "          entity_found = \"Entidade LOC encontrada\\n\"\n",
        "          intentions_predicates['send-info-location'] = True\n",
        "          entities_predicates['have-info-location'] = True\n",
        "        elif (i == 'CEP'):\n",
        "          entity_found = \"Entidade CEP encontrada\\n\"\n",
        "          intentions_predicates['send-info-postal-code'] = True\n",
        "          entities_predicates['have-info-postal-code'] = True\n",
        "        elif (i == 'GENERO'):\n",
        "          entity_found = \"Entidade GENERO encontrada\\n\"\n",
        "          intentions_predicates['send-info-gender'] = True\n",
        "          entities_predicates['have-info-gender'] = True\n",
        "        elif (i == 'TELEFONE'):\n",
        "          entity_found = \"Entidade TELEFONE encontrada\\n\"\n",
        "          intentions_predicates['send-info-phone-number'] = True\n",
        "          entities_predicates['have-info-phone-number'] = True\n",
        "\n",
        "      user_predicates.update(intentions_predicates)\n",
        "      user_predicates.update(entities_predicates)\n",
        "\n",
        "      return intentions_predicates, entities_predicates, user_predicates, entity_found"
      ],
      "metadata": {
        "id": "0rxUC0rYvgb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Análise dos diálogos do dataframe**"
      ],
      "metadata": {
        "id": "TEoDSanZvCRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extração dos predicados do usuário a cada interação do usuário\n",
        "\n",
        "file = open(\"/content/drive/MyDrive/user_predicates.txt\",\"w\")\n",
        "\n",
        "dialogs_with_human = 0\n",
        "\n",
        "for i in range(id_dialogos.size):\n",
        "  initial_predicates = predicates()\n",
        "  int_predicates = initial_predicates[0]\n",
        "  ent_predicates = initial_predicates[1]\n",
        "  dialog = df_by_id_chat.loc[id_dialogos[i]]\n",
        "  if (isinstance(dialog,pd.DataFrame)):\n",
        "    if dialog.astype(str).isin(['human']).any().any():\n",
        "      dialogs_with_human += 1\n",
        "    else:\n",
        "      line = 'Predicados do diálogo ' + str(i) + '\\n'\n",
        "      file.writelines(line)\n",
        "      line = 'Predicados iniciais do usuário: ' + str(initial_predicates) + '\\n'\n",
        "      file.writelines(line)\n",
        "      for index, row in dialog.iterrows():\n",
        "        if (row['ori'] == 'patient'):\n",
        "          results = predicates_extraction(row.txt, int_predicates, ent_predicates)\n",
        "          int_predicates = results[0]\n",
        "          ent_predicates = results[1]\n",
        "          file.write(str(results[3]))\n",
        "          file.write(str(results[2]))\n",
        "          file.write('\\n')\n",
        "      file.write('\\n')\n",
        "\n",
        "file.close()"
      ],
      "metadata": {
        "id": "6T33dy_CvnBg",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}